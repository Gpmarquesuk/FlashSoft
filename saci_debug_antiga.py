"""
SACI ANTIGA - Debug dos Problemas da SACI EVOLUÃDA

Submete 2 problemas crÃ­ticos encontrados nos testes para debate:
1. Bug de embeddings (similaridade sempre 0.0)
2. Threshold 0.75 muito alto (max atingido: 0.34)

Usa a SACI ANTIGA (sem mÃ©tricas quantitativas) para obter diagnÃ³stico.
"""

import asyncio
from llm_client import chat

# Contexto detalhado dos problemas
PROBLEMA_CONTEXT = """
# PROBLEMAS ENCONTRADOS NA SACI EVOLUÃDA

## CONTEXTO
Durante testes da SACI EVOLUÃDA (implementada com consenso 4/4 models), 
foram identificados 2 problemas crÃ­ticos em 15 rodadas de debates reais:

## PROBLEMA 1: Similaridade SemÃ¢ntica Sempre 0.0

**EvidÃªncias:**
- Debate 1 (IntegraÃ§Ã£o FlashSoft): 5 rodadas, todas com similarity=0.000
- Debate 2 (vs. Devin): 5 rodadas, todas com similarity=0.000
- Debate Teste (Database): 5 rodadas, todas com similarity=0.000

**ImplementaÃ§Ã£o:**
```python
def compute_semantic_similarity(texts: List[str], timeout: int = 10) -> float:
    try:
        client = OpenAI()
        embeddings = []
        for text in texts:
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=text[:8000]  # Truncate
            )
            embeddings.append(response.data[0].embedding)
        
        # Cosine similarity entre todos os pares
        similarities = []
        for i in range(len(embeddings)):
            for j in range(i+1, len(embeddings)):
                cos_sim = np.dot(embeddings[i], embeddings[j]) / (
                    np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])
                )
                similarities.append(cos_sim)
        
        return float(np.mean(similarities))
    except Exception:
        return 0.0  # Fallback
```

**HipÃ³teses:**
- A) ExceÃ§Ã£o silenciosa sempre (fallback 0.0)
- B) API OpenAI nÃ£o configurada/timeout
- C) Embeddings calculados mas similarity incorreta
- D) Bug no cÃ¡lculo de cosine similarity

**Impacto:**
- Score mÃ¡ximo possÃ­vel = 0.4 (apenas votos)
- Early stopping nunca ativa (threshold 0.75 inatingÃ­vel)
- MÃ©trica de convergÃªncia degenerada

---

## PROBLEMA 2: Threshold 0.75 Muito Alto

**EvidÃªncias:**
- Debate 1: Consenso claro (75% votos D), mas score max=0.339
- Debate 2: DivergÃªncia real, score max=0.162
- Debate Teste: Score max=0.248

**CÃ¡lculo Atual:**
```python
score = (semantic_weight * similarity) + (vote_weight * vote_consensus)
      = (0.6 * 0.000) + (0.4 * vote_consensus)
      = 0.4 * vote_consensus

# Para atingir 0.75:
0.4 * vote_consensus >= 0.75
vote_consensus >= 1.875  # IMPOSSÃVEL (max=1.0)
```

**HipÃ³teses:**
- A) Threshold deveria ser 0.40 (apenas votos)
- B) Pesos deveriam ser invertidos (0.4 semantic, 0.6 votes)
- C) Threshold deveria ser adaptativo baseado em rounds
- D) Bug de embeddings mascara problema real de threshold

**Impacto:**
- Early stopping nunca ativa
- Debates sempre vÃ£o atÃ© max_rounds (5)
- Custo e latÃªncia desnecessÃ¡rios

---

## DADOS REAIS DOS TESTES

### Debate 1 (IntegraÃ§Ã£o FlashSoft)
| Rodada | Similarity | Votos | Score | Consenso? |
|--------|-----------|-------|-------|-----------|
| 1 | 0.000 | d:3, c:1 | 0.339 | 75% em D |
| 2 | 0.000 | d:3, c:1 | 0.335 | 75% em D |
| 3 | 0.000 | d:3, c:1 | 0.335 | 75% em D |
| 4 | 0.000 | d:3, c:1 | 0.338 | 75% em D |
| 5 | 0.000 | d:3, c:1 | 0.339 | 75% em D |

**Resultado:** Consenso claro, mas score insuficiente para early stopping.

### Debate 2 (vs. Devin)
| Rodada | Similarity | Votos | Score | Consenso? |
|--------|-----------|-------|-------|-----------|
| 1 | 0.000 | c:3, d:1 | 0.129 | 75% em C |
| 2 | 0.000 | c:3, d:1 | 0.145 | 75% em C |
| 3 | 0.000 | c:3, d:1 | 0.154 | 75% em C |
| 4 | 0.000 | c:3, d:1 | 0.162 | 75% em C |
| 5 | 0.000 | c:3, d:1 | 0.153 | 75% em C |

**Resultado:** Consenso claro, mas score ainda mais baixo.

---

## QUESTÃ•ES PARA DEBATE

1. **Causa Raiz do Bug de Embeddings:**
   - Ã‰ problema de implementaÃ§Ã£o, configuraÃ§Ã£o ou design?
   - Fallback silencioso Ã© apropriado ou deveria falhar ruidosamente?

2. **Design de Threshold:**
   - 0.75 Ã© realista se embeddings funcionassem?
   - Deveria ser adaptativo (variar com nÃºmero de rodadas)?

3. **Pesos de MÃ©tricas:**
   - 0.6 semantic + 0.4 votes Ã© correto?
   - Ou deveria priorizar votos (mais confiÃ¡veis)?

4. **Prioridade de Fix:**
   - Corrigir embeddings primeiro?
   - Ou ajustar threshold para funcionar sÃ³ com votos?

5. **Fallback Strategy:**
   - Sistema deveria continuar funcionando sem embeddings?
   - Ou deveria falhar explicitamente e exigir fix?
"""

DEBATE_PROMPT = """
VocÃª Ã© um modelo especializado em debugging e design de sistemas.

**PROBLEMA SUBMETIDO:**
{context}

**SUA TAREFA:**
1. Analise as evidÃªncias apresentadas
2. Priorize os problemas por severidade e impacto
3. Proponha diagnÃ³stico para causa raiz de cada problema
4. Sugira ordem de correÃ§Ã£o (qual problema atacar primeiro)
5. Vote em UMA das opÃ§Ãµes:

**OPÃ‡Ã•ES DE DIAGNÃ“STICO:**

**A:** Bug de embeddings Ã© crÃ­tico, fix imediato (threshold Ã© consequÃªncia)
**B:** Threshold estÃ¡ errado, ajustar primeiro (embeddings podem esperar)
**C:** Design fundamentalmente falho, refatorar mÃ©tricas completamente
**D:** Ambos sÃ£o bugs independentes, corrigir em paralelo
**E:** Sistema funciona bem sÃ³ com votos, remover embeddings

**FORMATO DE RESPOSTA:**
```json
{{
  "diagnostico": "Sua anÃ¡lise detalhada das causas raiz",
  "prioridade": ["problema_1", "problema_2", ...],
  "causa_raiz_embeddings": "HipÃ³tese mais provÃ¡vel (A/B/C/D)",
  "causa_raiz_threshold": "HipÃ³tese mais provÃ¡vel (A/B/C/D)",
  "ordem_correcao": "Qual problema atacar primeiro e por quÃª",
  "impacto_estimado": "Severidade 1-10 para cada problema",
  "voto": "A/B/C/D/E",
  "confianca": 80
}}
```

Seja brutalmente honesto e tÃ©cnico. Priorize evidÃªncias empÃ­ricas.
"""

async def run_saci_antiga_debug():
    """Executa debate com SACI antiga sobre os problemas."""
    
    models = [
        "openai/o3-mini",
        "anthropic/claude-3.7-sonnet",
        "google/gemini-2.0-flash-exp:free",
        "meta-llama/llama-3.3-70b-instruct"
    ]
    
    print("\n" + "="*80)
    print("ğŸ” SACI ANTIGA - DEBUG DOS PROBLEMAS DA SACI EVOLUÃDA")
    print("="*80)
    print(f"\nğŸ“‹ Modelos participantes: {len(models)}")
    for i, model in enumerate(models, 1):
        print(f"   {i}. {model}")
    
    print("\nğŸ¯ Iniciando rodada de diagnÃ³stico...\n")
    
    responses = []
    
    # Rodada Ãºnica (SACI antiga nÃ£o tem rodadas mÃºltiplas formais)
    for i, model in enumerate(models, 1):
        print(f"â³ Consultando {model.split('/')[-1]}...")
        
        try:
            prompt = DEBATE_PROMPT.format(context=PROBLEMA_CONTEXT)
            
            content = await asyncio.to_thread(
                chat,
                model=model,
                system="VocÃª Ã© um especialista em debugging e design de sistemas.",
                user=prompt,
                temperature=0.7,
                max_tokens=2000
            )
            responses.append({
                "model": model,
                "response": content
            })
            
            print(f"âœ… Resposta recebida ({len(content)} chars)\n")
            
        except Exception as e:
            print(f"âŒ Erro ao consultar {model}: {e}\n")
            responses.append({
                "model": model,
                "response": f"ERROR: {str(e)}"
            })
    
    # Salvar resultados
    print("\n" + "="*80)
    print("ğŸ’¾ Salvando resultados...")
    print("="*80 + "\n")
    
    # Markdown formatado
    with open("logs/saci_antiga_debug_problemas.md", "w", encoding="utf-8") as f:
        f.write("# SACI ANTIGA - DIAGNÃ“STICO DOS PROBLEMAS DA SACI EVOLUÃDA\n\n")
        f.write(f"**Data:** {asyncio.get_event_loop().time()}\n")
        f.write(f"**Modelos:** {len(models)}\n\n")
        f.write("---\n\n")
        
        for i, resp in enumerate(responses, 1):
            model_name = resp['model'].split('/')[-1]
            f.write(f"## ğŸ¤– RESPOSTA {i}: {model_name}\n\n")
            f.write(f"**Model ID:** `{resp['model']}`\n\n")
            f.write("### DiagnÃ³stico:\n\n")
            f.write(resp['response'])
            f.write("\n\n---\n\n")
        
        # AnÃ¡lise de consenso (manual)
        f.write("## ğŸ“Š ANÃLISE DE CONSENSO\n\n")
        f.write("**PrÃ³ximo passo:** Revisar os 4 diagnÃ³sticos e identificar:\n")
        f.write("1. Qual hipÃ³tese de causa raiz tem mais suporte?\n")
        f.write("2. Qual problema atacar primeiro?\n")
        f.write("3. Qual estratÃ©gia de correÃ§Ã£o usar?\n\n")
        f.write("**Votos extraÃ­dos:** (revisar manualmente no JSON de cada resposta)\n")
    
    print("âœ… Resultados salvos em: logs/saci_antiga_debug_problemas.md")
    
    # Exibir preview
    print("\n" + "="*80)
    print("ğŸ“„ PREVIEW DAS RESPOSTAS")
    print("="*80 + "\n")
    
    for i, resp in enumerate(responses, 1):
        model_name = resp['model'].split('/')[-1]
        preview = resp['response'][:300] + "..." if len(resp['response']) > 300 else resp['response']
        print(f"ğŸ¤– {model_name}:")
        print(preview)
        print("\n" + "-"*80 + "\n")
    
    print("âœ… Debate concluÃ­do!")
    print(f"ğŸ“Š {len(responses)}/{len(models)} modelos responderam")
    print("ğŸ“ AnÃ¡lise completa disponÃ­vel em: logs/saci_antiga_debug_problemas.md\n")

if __name__ == "__main__":
    asyncio.run(run_saci_antiga_debug())
