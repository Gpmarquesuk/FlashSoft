#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SACI v1.0 - Sistema Avan√ßado de Converg√™ncia de Ideias
========================================================

VERS√ÉO OFICIAL E EST√ÅVEL para uso em produ√ß√£o.

DEFINI√á√ÉO:
----------
SACI = 4 modelos espec√≠ficos de IA que debatem at√© obter consenso majorit√°rio (3/4).

MODELOS OFICIAIS (N√ÉO ALTERAR):
---------------------------------
1. Claude Sonnet 4.5  (anthropic/claude-sonnet-4.5)
2. GPT-5 Codex        (openai/gpt-5-codex)
3. Gemini 2.5 PRO     (google/gemini-2.5-pro)
4. Grok 4             (x-ai/grok-4)

USO:
----
    from saci_v1 import debate_saci
    
    problema = "Qual banco de dados usar: PostgreSQL ou MongoDB?"
    contexto = "Sistema de e-commerce com transa√ß√µes cr√≠ticas..."
    
    resultado = debate_saci(
        problema=problema,
        contexto=contexto,
        max_rodadas=3
    )
    
    print(f"Consenso: {resultado['consenso']}")
    print(f"Solu√ß√£o: {resultado['solucao_final']}")

ROADMAP:
--------
- SACI v1.0: Vers√£o atual (est√°vel, sem m√©tricas quantitativas)
- SACI v2.0: SACI EVOLU√çDA (em desenvolvimento no diret√≥rio saci/)
  - M√©tricas de converg√™ncia sem√¢ntica
  - Early stopping inteligente
  - Rastreabilidade JSON completa

QUANDO MIGRAR PARA v2.0:
------------------------
Apenas quando SACI v2.0 demonstrar superioridade comprovada em testes reais.
At√© l√°, USE SACI v1.0 para todos os debates de produ√ß√£o.

Autor: FlashSoft Team
Data: 24/10/2025
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, List, Optional
from llm_client import chat

# ============================================================================
# CONFIGURA√á√ÉO OFICIAL DA SACI v1.0
# ============================================================================

SACI_MODELS = {
    'claude': {
        'id': 'anthropic/claude-sonnet-4.5',
        'name': 'Claude Sonnet 4.5',
        'specialty': 'System architecture, technical analysis'
    },
    'codex': {
        'id': 'openai/gpt-5-codex',
        'name': 'GPT-5 Codex',
        'specialty': 'Code design, implementation patterns'
    },
    'gemini': {
        'id': 'google/gemini-2.5-pro',
        'name': 'Gemini 2.5 PRO',
        'specialty': 'Strategic analysis, trade-off evaluation'
    },
    'grok': {
        'id': 'x-ai/grok-4',
        'name': 'Grok 4',
        'specialty': 'Critical thinking, edge case analysis'
    }
}

DELAY_BETWEEN_CALLS = 2  # segundos

# ============================================================================
# FUN√á√ïES PRINCIPAIS
# ============================================================================

def debate_saci(
    problema: str,
    contexto: str = "",
    max_rodadas: int = 3,
    threshold_consenso: float = 0.75,
    output_dir: str = "logs",
    verbose: bool = True
) -> Dict:
    """
    Executa um debate SACI v1.0 completo.
    
    Args:
        problema: Quest√£o/problema a ser debatido
        contexto: Contexto adicional relevante
        max_rodadas: N√∫mero m√°ximo de rodadas de debate
        threshold_consenso: % de concord√¢ncia necess√°ria (0.75 = 3/4)
        output_dir: Diret√≥rio para salvar logs
        verbose: Imprimir progresso no console
        
    Returns:
        Dict com:
        - consenso: bool (True se atingiu consenso)
        - solucao_final: str (solu√ß√£o consensual ou s√≠ntese)
        - votos: Dict (distribui√ß√£o de votos)
        - rodadas: List (hist√≥rico completo)
        - timestamp: str
    """
    
    if verbose:
        print("\n" + "="*80)
        print("üß† SACI v1.0 - DEBATE INICIADO")
        print("="*80)
        print(f"\nüìã Problema: {problema[:100]}...")
        print(f"üéØ Threshold: {threshold_consenso*100}% ({int(threshold_consenso*4)}/4 modelos)")
        print(f"üîÑ Max rodadas: {max_rodadas}\n")
    
    os.makedirs(output_dir, exist_ok=True)
    
    historico = []
    consenso_atingido = False
    solucao_final = None
    
    # RODADAS DE DEBATE
    for rodada_num in range(1, max_rodadas + 1):
        if verbose:
            print(f"\n{'='*80}")
            print(f"üîÑ RODADA {rodada_num}/{max_rodadas}")
            print(f"{'='*80}\n")
        
        rodada_data = {
            'numero': rodada_num,
            'respostas': {},
            'timestamp': datetime.now().isoformat()
        }
        
        # Construir prompt da rodada
        if rodada_num == 1:
            prompt = _build_initial_prompt(problema, contexto)
        else:
            prompt = _build_followup_prompt(problema, contexto, historico)
        
        # Consultar cada modelo
        for model_key, model_info in SACI_MODELS.items():
            if verbose:
                print(f"‚è≥ Consultando {model_info['name']}...")
            
            try:
                response = chat(
                    model=model_info['id'],
                    system=f"You are an expert in {model_info['specialty']}. Participate in structured debate with other AI models to reach consensus.",
                    user=prompt,
                    temperature=0.4,
                    max_tokens=2000
                )
                
                rodada_data['respostas'][model_key] = {
                    'model_name': model_info['name'],
                    'model_id': model_info['id'],
                    'response': response,
                    'success': True
                }
                
                if verbose:
                    print(f"‚úÖ {model_info['name']}: {len(response)} chars")
                
            except Exception as e:
                if verbose:
                    print(f"‚ùå {model_info['name']}: ERROR - {e}")
                
                rodada_data['respostas'][model_key] = {
                    'model_name': model_info['name'],
                    'model_id': model_info['id'],
                    'response': None,
                    'success': False,
                    'error': str(e)
                }
            
            # Delay entre chamadas
            if model_key != list(SACI_MODELS.keys())[-1]:
                time.sleep(DELAY_BETWEEN_CALLS)
        
        historico.append(rodada_data)
        
        # VERIFICAR CONSENSO
        votos = _extract_votes(rodada_data['respostas'])
        consenso_atingido, solucao_final = _check_consensus(
            votos, 
            threshold_consenso,
            rodada_data['respostas']
        )
        
        if verbose:
            print(f"\nüìä Votos da rodada {rodada_num}: {votos}")
        
        if consenso_atingido:
            if verbose:
                print(f"‚úÖ CONSENSO ATINGIDO!")
            break
    
    # RESULTADO FINAL
    resultado = {
        'consenso': consenso_atingido,
        'solucao_final': solucao_final,
        'votos': votos if consenso_atingido else {},
        'rodadas': historico,
        'timestamp': datetime.now().isoformat(),
        'versao': '1.0'
    }
    
    # Salvar log
    log_filename = f"{output_dir}/saci_debate_{int(time.time())}.json"
    with open(log_filename, 'w', encoding='utf-8') as f:
        json.dump(resultado, f, ensure_ascii=False, indent=2)
    
    if verbose:
        print(f"\n{'='*80}")
        print("üìÅ DEBATE FINALIZADO")
        print(f"{'='*80}")
        print(f"‚úÖ Consenso: {'SIM' if consenso_atingido else 'N√ÉO'}")
        print(f"üìÑ Log salvo: {log_filename}\n")
    
    return resultado


def _build_initial_prompt(problema: str, contexto: str) -> str:
    """Constr√≥i prompt da primeira rodada."""
    return f"""# DEBATE SACI v1.0 - RODADA 1

## PROBLEMA A RESOLVER:
{problema}

## CONTEXTO:
{contexto if contexto else "N/A"}

## SUA TAREFA:
1. Analise o problema apresentado
2. Proponha uma solu√ß√£o clara e justificada
3. Ao final, vote em UMA op√ß√£o (se houver op√ß√µes expl√≠citas) ou proponha sua pr√≥pria solu√ß√£o
4. Seja t√©cnico, objetivo e conciso

## FORMATO DE RESPOSTA:
- An√°lise: [sua an√°lise]
- Proposta: [sua solu√ß√£o/recomenda√ß√£o]
- Voto: [sua escolha final]
- Justificativa: [por que esta √© a melhor op√ß√£o]

Responda de forma estruturada e t√©cnica.
"""


def _build_followup_prompt(problema: str, contexto: str, historico: List[Dict]) -> str:
    """Constr√≥i prompt das rodadas subsequentes."""
    ultima_rodada = historico[-1]
    rodada_num = len(historico) + 1
    
    prompt = f"""# DEBATE SACI v1.0 - RODADA {rodada_num}

## PROBLEMA ORIGINAL:
{problema}

## RESPOSTAS DA RODADA ANTERIOR:

"""
    
    for model_key, resp_data in ultima_rodada['respostas'].items():
        if resp_data['success']:
            prompt += f"\n{'='*60}\n"
            prompt += f"üí¨ {resp_data['model_name']}:\n"
            prompt += f"{'='*60}\n"
            prompt += resp_data['response'][:800] + "...\n"
    
    prompt += f"""

## SUA TAREFA:
1. Avalie as propostas dos outros modelos
2. Identifique pontos de consenso e diverg√™ncia
3. Refine sua proposta ou adote a melhor proposta apresentada
4. Vote claramente na solu√ß√£o final que voc√™ apoia

## OBJETIVO:
Convergir para uma solu√ß√£o consensual. Se concordar com outro modelo, DECLARE explicitamente.

Responda de forma estruturada indicando seu voto final.
"""
    
    return prompt


def _extract_votes(respostas: Dict) -> Dict:
    """
    Extrai votos das respostas dos modelos.
    
    Estrat√©gia simples: conta palavras-chave como "PostgreSQL", "MongoDB", etc.
    Para v2.0, usaremos parsing JSON estruturado.
    """
    votos = {}
    
    for model_key, resp_data in respostas.items():
        if not resp_data['success']:
            continue
        
        response_lower = resp_data['response'].lower()
        
        # Extra√ß√£o simples baseada em keywords
        # TODO: melhorar para v2.0 com JSON estruturado
        voto = "unclear"
        
        # Buscar padr√µes de voto expl√≠cito
        if "voto:" in response_lower or "vote:" in response_lower:
            # Extrair ap√≥s "voto:"
            parts = response_lower.split("voto:")
            if len(parts) > 1:
                voto_section = parts[1][:200]
                # Primeira palavra significativa
                words = voto_section.split()
                if words:
                    voto = words[0].strip('.,;:!?')
        
        votos[model_key] = voto
    
    return votos


def _check_consensus(votos: Dict, threshold: float, respostas: Dict) -> tuple:
    """
    Verifica se houve consenso.
    
    Returns:
        (consenso_atingido: bool, solucao_final: str)
    """
    if not votos:
        return False, None
    
    # Contar votos
    contagem = {}
    for voto in votos.values():
        contagem[voto] = contagem.get(voto, 0) + 1
    
    total_votos = len(votos)
    voto_majoritario = max(contagem, key=contagem.get)
    qtd_majoritaria = contagem[voto_majoritario]
    
    percentual = qtd_majoritaria / total_votos
    
    if percentual >= threshold:
        # Consenso atingido - sintetizar solu√ß√£o
        solucao = f"Consenso: {voto_majoritario} ({qtd_majoritaria}/{total_votos} votos = {percentual*100:.0f}%)"
        
        # Adicionar justificativas dos modelos que votaram pela op√ß√£o vencedora
        for model_key, voto in votos.items():
            if voto == voto_majoritario and respostas[model_key]['success']:
                resp = respostas[model_key]['response'][:500]
                solucao += f"\n\n{respostas[model_key]['model_name']}: {resp}..."
        
        return True, solucao
    
    return False, None


# ============================================================================
# FUN√á√ïES AUXILIARES
# ============================================================================

def verificar_saci_disponivel() -> Dict[str, bool]:
    """
    Verifica se todos os modelos da SACI est√£o dispon√≠veis.
    
    Returns:
        Dict com status de cada modelo
    """
    status = {}
    
    for model_key, model_info in SACI_MODELS.items():
        try:
            # Teste r√°pido com prompt m√≠nimo
            response = chat(
                model=model_info['id'],
                system="Test",
                user="Respond with 'OK'",
                max_tokens=10,
                temperature=0
            )
            status[model_key] = True
        except Exception as e:
            status[model_key] = False
            print(f"‚ùå {model_info['name']}: {e}")
    
    return status


def get_saci_info() -> Dict:
    """Retorna informa√ß√µes sobre a SACI v1.0."""
    return {
        'versao': '1.0',
        'modelos': SACI_MODELS,
        'threshold_consenso': 0.75,
        'descricao': 'Sistema Avan√ßado de Converg√™ncia de Ideias - Vers√£o est√°vel',
        'proxima_versao': '2.0 (SACI EVOLU√çDA - em desenvolvimento)',
        'quando_migrar': 'Apenas quando v2.0 demonstrar superioridade comprovada'
    }


# ============================================================================
# EXEMPLO DE USO
# ============================================================================

if __name__ == "__main__":
    # Exemplo simples
    resultado = debate_saci(
        problema="Qual banco de dados √© mais adequado para um e-commerce: PostgreSQL ou MongoDB?",
        contexto="Sistema com alta consist√™ncia transacional, volume m√©dio (100k pedidos/dia), equipe pequena.",
        max_rodadas=2
    )
    
    print("\n" + "="*80)
    print("RESULTADO FINAL")
    print("="*80)
    print(f"\nConsenso: {resultado['consenso']}")
    if resultado['consenso']:
        print(f"\nSolu√ß√£o:\n{resultado['solucao_final']}")
    print(f"\nRodadas executadas: {len(resultado['rodadas'])}")
