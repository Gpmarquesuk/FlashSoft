# SACI - Sistema Avan√ßado de Converg√™ncia de Ideias

**Vers√£o:** 1.0  
**Data:** 2025-10-23  
**Baseado em:** Consulta a 4 especialistas (Gemini 2.5 PRO, GPT-5 CODEX, Grok 4, Claude 3.5 Sonnet)

---

## üìã SUM√ÅRIO EXECUTIVO

### O que √© a SACI?
Sistema de debate estruturado entre 4 modelos de IA que convergem iterativamente at√© obter **consenso majorit√°rio** (3 de 4) sobre solu√ß√µes para problemas complexos.

### Por que criar?
- Solu√ß√µes por agente √∫nico s√£o limitadas e enviesadas
- Consultas paralelas n√£o produzem converg√™ncia real
- Problemas cr√≠ticos da FlashSoft exigem "intelig√™ncia coletiva"

### Aplica√ß√µes
- Decis√µes arquiteturais cr√≠ticas
- Debugging de problemas complexos  
- Design de componentes-chave
- Valida√ß√£o de estrat√©gias
- **Uso imediato:** Validar recomenda√ß√µes anteriores sobre a f√°brica

---

## üèóÔ∏è ARQUITETURA CONSENSUAL

### **CONSENSO DOS 4 ESPECIALISTAS:**

#### 1. Estrutura de Orquestrador Centralizado
**Todos concordam:** Motor central que gerencia:
- Estado do debate (hist√≥rico, propostas, votos)
- Progress√£o de fases
- Detec√ß√£o de converg√™ncia
- Persist√™ncia e logging

#### 2. Protocolo de 3-5 Rodadas
**Converg√™ncia:**
- **M√≠nimo:** 3 rodadas (proposta ‚Üí cr√≠tica ‚Üí refinamento)
- **M√°ximo:** 5 rodadas (evita loops infinitos)
- **Ideal:** 4 rodadas com converg√™ncia em rodada 3-4

#### 3. Fases do Debate
**Consenso sobre estrutura:**
1. **Initial Proposal** (Rodada 1): Cada agente prop√µe solu√ß√£o independente
2. **Critique** (Rodada 2): Agentes criticam propostas dos outros (strengths/weaknesses)
3. **Refinement** (Rodada 3): Agentes refinam propostas baseado em cr√≠ticas
4. **Convergence** (Rodada 4): S√≠ntese colaborativa
5. **Final Vote** (Rodada 5): Vota√ß√£o com justificativas

#### 4. Detec√ß√£o de Converg√™ncia
**M√©tricas m√∫ltiplas** (n√£o apenas vota√ß√£o):
- **Similaridade sem√¢ntica** entre propostas (embeddings + cosine similarity)
- **Alinhamento de votos** (>= 75% concordam)
- **Severidade de cr√≠ticas** (redu√ß√£o ao longo das rodadas)
- **Delta entre itera√ß√µes** (mudan√ßas diminuem)

**Converg√™ncia detectada quando:** 2+ m√©tricas > 75% threshold

---

## ü§ñ SELE√á√ÉO DOS 4 MODELOS

### **RECOMENDA√á√ÉO CONSENSUAL:**

| Posi√ß√£o | Modelo | Justificativa |
|---------|--------|---------------|
| **Agente 1** | **Claude 3.5 Sonnet** | Racioc√≠nio profundo, cr√≠ticas construtivas |
| **Agente 2** | **GPT-4o** (ou O1 Pro) | An√°lise balanceada, sintetiza√ß√£o |
| **Agente 3** | **Gemini 2.5 Pro** | Vis√£o t√©cnica, arquitetura |
| **Agente 4** | **Grok 4** (ou Codex) | Perspectiva alternativa, code-focused |

### Crit√©rios de Sele√ß√£o:
- ‚úÖ **Diversidade de "fam√≠lias"** (Anthropic, OpenAI, Google, xAI)
- ‚úÖ **Especialidades complementares**
- ‚úÖ **Suporte a structured output** (JSON native)
- ‚úÖ **Context window adequado** (100k+ tokens)

---

## üîß IMPLEMENTA√á√ÉO T√âCNICA

### Stack Recomendado (Consenso):
```python
# Core
- Python 3.11+
- Pydantic v2 (structured data + validation)
- asyncio (debates ass√≠ncronos)

# LLM Orchestration
- OpenAI SDK (para todos via OpenRouter)
- tenacity (retry logic)

# Converg√™ncia
- sentence-transformers (embeddings para similaridade)
- scikit-learn (cosine similarity)

# Persist√™ncia
- SQLModel (ORM com Pydantic)
- SQLite (desenvolvimento) ‚Üí PostgreSQL (produ√ß√£o)

# Monitoring
- structlog (logging estruturado)
- MLflow (tracking de debates)
```

### Estrutura de Dados Core (Pydantic):

```python
from typing import List, Dict, Literal
from pydantic import BaseModel, Field
from enum import Enum
from datetime import datetime

class DebatePhase(str, Enum):
    INITIAL_PROPOSAL = "initial_proposal"
    CRITIQUE = "critique"
    REFINEMENT = "refinement"
    CONVERGENCE = "convergence"
    FINAL_VOTE = "final_vote"

class Proposal(BaseModel):
    """Proposta de solu√ß√£o de um agente"""
    id: str
    agent_id: str
    content: str  # Solu√ß√£o proposta
    reasoning: str  # Justificativa
    phase: DebatePhase
    timestamp: datetime
    references: List[str] = []  # IDs de propostas influentes
    confidence: float = Field(ge=0.0, le=1.0, default=0.7)

class Critique(BaseModel):
    """Cr√≠tica estruturada de uma proposta"""
    critic_id: str
    target_proposal_id: str
    strengths: List[str]
    weaknesses: List[str]
    suggestions: List[str]
    severity: Literal["minor", "moderate", "critical"]

class Vote(BaseModel):
    """Voto em proposta final"""
    voter_id: str
    proposal_id: str
    support: Literal["strong_agree", "agree", "neutral", "disagree", "strong_disagree"]
    reasoning: str

class ConvergenceMetrics(BaseModel):
    """M√©tricas de converg√™ncia"""
    round: int
    proposal_similarity: float  # 0-1
    vote_alignment: float  # 0-1
    critique_severity: float  # 0-1 (m√©dia)
    consensus_strength: float  # 0-1 (combina√ß√£o)
    
    def is_converged(self, threshold: float = 0.75) -> bool:
        """Convergido quando >=2 m√©tricas > threshold"""
        metrics = [
            self.proposal_similarity,
            self.vote_alignment,
            1 - self.critique_severity  # Invertido
        ]
        return sum(m > threshold for m in metrics) >= 2

class DebateResult(BaseModel):
    """Resultado final do debate"""
    problem: str
    consensus_proposal: Proposal
    convergence_metrics: ConvergenceMetrics
    rounds_taken: int
    total_duration_seconds: float
    votes: List[Vote]
    debate_history: List[Dict]  # Log completo
```

---

## üîÑ PROTOCOLO DE DEBATE DETALHADO

### **Rodada 1: Initial Proposal**
```
Para cada agente (paralelo):
  Prompt: "Analise o problema: {problem}. Proponha solu√ß√£o detalhada."
  Output: Proposal(content, reasoning, confidence)
```

### **Rodada 2: Critique**
```
Para cada agente:
  Context: Todas as 4 propostas da Rodada 1
  Prompt: "Critique as propostas dos outros. Identifique strengths, weaknesses, suggestions."
  Output: List[Critique] (3 cr√≠ticas, uma para cada proposta dos outros)
```

### **Rodada 3: Refinement**
```
Para cada agente:
  Context: Sua proposta original + cr√≠ticas recebidas
  Prompt: "Refine sua proposta baseado nas cr√≠ticas. Incorpore sugest√µes v√°lidas."
  Output: Proposal(refined_content, reasoning)
```

### **Rodada 4: Convergence Check**
```
Sistema calcula:
  - Similaridade entre propostas refinadas (embeddings)
  - Identifica√ß√£o de proposta mais pr√≥xima do consenso
  
Se converg√™ncia >= 75%:
  ‚Üí Prossegue para Rodada 5
Sen√£o:
  ‚Üí Rodada extra de s√≠ntese for√ßada (facilitador Gemini)
```

### **Rodada 5: Final Vote**
```
Para cada agente:
  Context: Proposta de consenso identificada
  Prompt: "Vote na proposta final: strong_agree|agree|neutral|disagree|strong_disagree + justificativa"
  Output: Vote

Crit√©rio de aceita√ß√£o: >= 3 agentes com agree ou strong_agree
```

---

## üéØ MECANISMOS DE DESEMPATE

### **CONSENSO DOS ESPECIALISTAS:**

1. **Empate 2 vs 2:**
   - **Op√ß√£o A (preferida):** Convocar 5¬∫ modelo especializado (ex: GPT-5 Codex para c√≥digo, O1 Pro para racioc√≠nio)
   - **Op√ß√£o B:** Human-in-the-loop (usu√°rio decide)
   - **Op√ß√£o C:** Usar m√©tricas de converg√™ncia (proposta com maior similaridade sem√¢ntica)

2. **Sem converg√™ncia ap√≥s 5 rodadas:**
   - **Op√ß√£o A:** Declarar "no consensus" e apresentar 2-3 melhores propostas ao usu√°rio
   - **Op√ß√£o B:** Rodada de "forced synthesis" (Gemini como facilitador cria s√≠ntese h√≠brida)
   - **Op√ß√£o C:** Reduzir escopo do problema e tentar novamente

3. **Diverg√™ncia crescente:**
   - Sistema detecta se cr√≠ticas ficam mais severas entre rodadas
   - Se detectado: pausa autom√°tica, reformula problema com mais contexto, reinicia

---

## üíª PSEUDOC√ìDIGO IMPLEMENTA√á√ÉO

```python
class SACIEngine:
    def __init__(self, agents: List[Agent], max_rounds=5, threshold=0.75):
        self.agents = agents
        self.max_rounds = max_rounds
        self.threshold = threshold
        self.debate_history = []
        
    async def run_debate(self, problem: str) -> DebateResult:
        """Executa debate completo at√© converg√™ncia"""
        
        # RODADA 1: Propostas iniciais
        proposals = await self.round_initial_proposals(problem)
        
        # RODADA 2: Cr√≠ticas
        critiques = await self.round_critiques(proposals)
        
        # RODADA 3: Refinamento
        refined_proposals = await self.round_refinement(proposals, critiques)
        
        # RODADA 4: Check converg√™ncia
        metrics = self.calculate_convergence(refined_proposals)
        
        if metrics.is_converged(self.threshold):
            # Convergiu! Identifica proposta consenso
            consensus_prop = self.identify_consensus_proposal(refined_proposals)
        else:
            # N√£o convergiu - for√ßar s√≠ntese
            consensus_prop = await self.forced_synthesis(refined_proposals)
        
        # RODADA 5: Vota√ß√£o final
        votes = await self.round_final_vote(consensus_prop)
        
        # Validar resultado
        if self.validate_votes(votes):
            return DebateResult(
                problem=problem,
                consensus_proposal=consensus_prop,
                convergence_metrics=metrics,
                rounds_taken=4 if metrics.is_converged() else 5,
                votes=votes,
                debate_history=self.debate_history
            )
        else:
            # Desempate necess√°rio
            return await self.handle_tie(problem, votes)
    
    async def round_initial_proposals(self, problem: str) -> List[Proposal]:
        """Rodada 1: Cada agente prop√µe solu√ß√£o"""
        tasks = [agent.propose(problem) for agent in self.agents]
        proposals = await asyncio.gather(*tasks)
        self.debate_history.append({"round": 1, "phase": "proposals", "data": proposals})
        return proposals
    
    async def round_critiques(self, proposals: List[Proposal]) -> List[Critique]:
        """Rodada 2: Agentes criticam propostas dos outros"""
        critiques = []
        for agent in self.agents:
            # Cada agente v√™ todas as propostas exceto a pr√≥pria
            other_proposals = [p for p in proposals if p.agent_id != agent.id]
            agent_critiques = await agent.critique(other_proposals)
            critiques.extend(agent_critiques)
        
        self.debate_history.append({"round": 2, "phase": "critiques", "data": critiques})
        return critiques
    
    async def round_refinement(self, proposals: List[Proposal], 
                               critiques: List[Critique]) -> List[Proposal]:
        """Rodada 3: Agentes refinam baseado em cr√≠ticas"""
        refined = []
        for agent in self.agents:
            # Filtrar cr√≠ticas recebidas por esse agente
            my_critiques = [c for c in critiques 
                           if any(p.id == c.target_proposal_id and p.agent_id == agent.id 
                                  for p in proposals)]
            
            my_proposal = next(p for p in proposals if p.agent_id == agent.id)
            refined_prop = await agent.refine(my_proposal, my_critiques)
            refined.append(refined_prop)
        
        self.debate_history.append({"round": 3, "phase": "refinement", "data": refined})
        return refined
    
    def calculate_convergence(self, proposals: List[Proposal]) -> ConvergenceMetrics:
        """Calcula m√©tricas de converg√™ncia"""
        from sentence_transformers import SentenceTransformer
        from sklearn.metrics.pairwise import cosine_similarity
        
        model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Embeddings das propostas
        contents = [p.content for p in proposals]
        embeddings = model.encode(contents)
        
        # Similaridade par a par
        similarities = cosine_similarity(embeddings)
        avg_similarity = similarities[np.triu_indices_from(similarities, k=1)].mean()
        
        # Outras m√©tricas (simplificado)
        avg_confidence = np.mean([p.confidence for p in proposals])
        
        return ConvergenceMetrics(
            round=3,
            proposal_similarity=float(avg_similarity),
            vote_alignment=0.0,  # Calculado na rodada 5
            critique_severity=0.3,  # Estimado
            consensus_strength=float(avg_similarity * avg_confidence)
        )
    
    def identify_consensus_proposal(self, proposals: List[Proposal]) -> Proposal:
        """Identifica proposta mais pr√≥xima do consenso"""
        # Usa similaridade sem√¢ntica para encontrar "centroide"
        # Simplificado: retorna proposta com maior confidence
        return max(proposals, key=lambda p: p.confidence)
    
    async def round_final_vote(self, consensus: Proposal) -> List[Vote]:
        """Rodada 5: Vota√ß√£o final"""
        tasks = [agent.vote(consensus) for agent in self.agents]
        votes = await asyncio.gather(*tasks)
        self.debate_history.append({"round": 5, "phase": "votes", "data": votes})
        return votes
    
    def validate_votes(self, votes: List[Vote]) -> bool:
        """Valida se h√° consenso majorit√°rio"""
        positive_votes = sum(1 for v in votes 
                            if v.support in ["agree", "strong_agree"])
        return positive_votes >= 3  # Maioria
    
    async def handle_tie(self, problem: str, votes: List[Vote]) -> DebateResult:
        """Desempate com 5¬∫ modelo"""
        tiebreaker_agent = Agent(model="openai/o1-pro", id="tiebreaker")
        
        # Contexto: problema + 4 votos
        tiebreaker_vote = await tiebreaker_agent.vote_with_context(
            problem=problem,
            votes=votes
        )
        
        # Retorna com flag de tiebreaker
        # ... (implementa√ß√£o completa)
```

---

## üöÄ EXEMPLO DE USO PR√ÅTICO

### Caso 1: Validar Recomenda√ß√µes Anteriores sobre F√°brica

```python
# Inicializar SACI
saci = SACIEngine(
    agents=[
        Agent(model="anthropic/claude-sonnet-4.5", id="claude"),
        Agent(model="openai/gpt-4o", id="gpt4o"),
        Agent(model="google/gemini-2.5-pro", id="gemini"),
        Agent(model="x-ai/grok-4", id="grok")
    ],
    max_rounds=5,
    threshold=0.75
)

# Definir problema
problem = """
A junta de especialistas recomendou:
1. Fixar Planner com Pydantic schema
2. Reduzir context window drasticamente
3. Simplificar committee de modelos
4. Criar UI com Streamlit

O usu√°rio questiona: "N√£o estou convencido de que esta √© a melhor estrat√©gia."

TAREFA SACI:
- Debater se essas recomenda√ß√µes s√£o realmente √≥timas
- Propor alternativas se houver consenso de que n√£o s√£o
- Convergir em estrat√©gia final validada por 4 modelos
"""

# Executar debate
result = await saci.run_debate(problem)

# Resultado
print(f"‚úì Consenso alcan√ßado em {result.rounds_taken} rodadas")
print(f"‚úì For√ßa do consenso: {result.convergence_metrics.consensus_strength:.0%}")
print(f"\nüìù SOLU√á√ÉO CONSENSUAL:\n{result.consensus_proposal.content}")
print(f"\nüìä VOTA√á√ÉO:")
for vote in result.votes:
    print(f"  {vote.voter_id}: {vote.support} - {vote.reasoning[:100]}...")
```

### Caso 2: Decis√£o Arquitetural da F√°brica

```python
problem = """
Decis√£o cr√≠tica: Formato de sa√≠da do Planner

OP√á√ïES:
A) JSON com c√≥digo completo: {"patches": [{"path": "...", "content": "..."}]}
B) Unified diff patches (git diff format)
C) Gera√ß√£o direta de arquivos .py no workspace (sem JSON)
D) Chunks estruturados com AST patches

Considerar:
- Context window limits
- Facilidade de parsing
- Robustez a erros
- Token efficiency

SACI: Convergir na melhor op√ß√£o com justificativa t√©cnica.
"""

result = await saci.run_debate(problem)
# Implementar solu√ß√£o escolhida com confian√ßa
```

---

## üìÖ ROADMAP DE IMPLEMENTA√á√ÉO

### **FASE 1: MVP (2-3 dias)**
- [ ] Implementar Pydantic models (Proposal, Critique, Vote, Metrics)
- [ ] Motor b√°sico com 3 rodadas (propose ‚Üí critique ‚Üí vote)
- [ ] Integra√ß√£o com OpenRouter (4 modelos via llm_client.py)
- [ ] C√°lculo simples de converg√™ncia (vota√ß√£o majorit√°ria)
- [ ] Teste com problema "toy" (ex: escolher nome de vari√°vel)

### **FASE 2: Core Completo (3-5 dias)**
- [ ] 5 rodadas completas com refinement
- [ ] Embeddings + cosine similarity para converg√™ncia sem√¢ntica
- [ ] Persist√™ncia com SQLModel
- [ ] Logging estruturado (structlog)
- [ ] Mecanismo de desempate (5¬∫ modelo)
- [ ] Teste com problema real da f√°brica

### **FASE 3: Produ√ß√£o (5-7 dias)**
- [ ] Timeout handling e retry logic
- [ ] UI com Streamlit para monitorar debates
- [ ] API FastAPI para integra√ß√£o externa
- [ ] MLflow tracking de debates
- [ ] Documenta√ß√£o completa
- [ ] Deploy como servi√ßo standalone

---

## üéØ APLICA√á√ÉO IMEDIATA √Ä F√ÅBRICA FLASHSOFT

### **Uso da SACI para Validar Estrat√©gia Atual:**

```python
# 1. Executar SACI sobre o pr√≥prio problema da f√°brica
problem_fabrica = """
CONTEXTO: FlashSoft factory falha 100% no Planner (Context Window Overflow).

RECOMENDA√á√ïES ANTERIORES:
- Pydantic schema para Planner output
- Truncar spec em 15 linhas
- Limitar a 2 arquivos
- Few-shot examples no prompt

QUEST√ÉO: Essa estrat√©gia resolver√° o problema raiz ou √© apenas paliativo?

ALTERNATIVAS A CONSIDERAR:
1. Refatorar Planner em sub-agentes (1 por arquivo)
2. Usar diffs em vez de JSON com c√≥digo completo
3. Gera√ß√£o incremental com valida√ß√£o a cada arquivo
4. Modelo especializado (Codex) em vez de Claude/Gemini

SACI: Convergir na estrat√©gia DEFINITIVA para o Planner.
"""

resultado = await saci.run_debate(problem_fabrica)

# 2. Implementar solu√ß√£o consensual com confian√ßa
implementar_solucao(resultado.consensus_proposal)
```

### **Vantagens da SACI vs Consulta Paralela Anterior:**
- ‚úÖ **Converg√™ncia real** (n√£o apenas 3 opini√µes independentes)
- ‚úÖ **Refinamento iterativo** (propostas melhoram com cr√≠ticas)
- ‚úÖ **Valida√ß√£o cruzada** (cada agente avalia os outros)
- ‚úÖ **Consenso fundamentado** (>=75% alignment em m√∫ltiplas m√©tricas)
- ‚úÖ **Rastreabilidade** (hist√≥rico completo do debate)

---

## üìö REFER√äNCIAS T√âCNICAS

### Frameworks Multi-Agent Consultados:
- **AutoGen** (Microsoft): https://github.com/microsoft/autogen
- **LangGraph** (LangChain): https://github.com/langchain-ai/langgraph
- **CrewAI**: https://github.com/joaomdmoura/crewAI

### Papers Acad√™micos:
- "Multi-Agent Debate" (Du et al., 2023): https://arxiv.org/abs/2305.14325
- "ReAct: Synergizing Reasoning and Acting in LLMs" (Yao et al., 2022)
- "Constitutional AI" (Anthropic): Debate interno entre modelos

### Consensus Algorithms:
- Raft (consensus for distributed systems)
- Paxos (Byzantine fault tolerance)
- Majority voting with confidence weighting

---

## üèÅ PR√ìXIMOS PASSOS IMEDIATOS

1. **HOJE:**
   - ‚úÖ Consulta META conclu√≠da (4/4 especialistas)
   - ‚úÖ Especifica√ß√£o SACI criada
   - [ ] Revisar e aprovar spec com usu√°rio

2. **AMANH√É:**
   - [ ] Implementar Pydantic models (SACI_SPEC ‚Üí c√≥digo)
   - [ ] Motor MVP com 3 rodadas
   - [ ] Teste com problema toy

3. **DIA 3:**
   - [ ] Rodar SACI sobre problema da f√°brica
   - [ ] Implementar solu√ß√£o consensual
   - [ ] Validar com execu√ß√£o real

---

## üìä M√âTRICAS DE SUCESSO

### Curto Prazo (1 semana)
- [ ] SACI MVP funcional (3 rodadas, vota√ß√£o simples)
- [ ] 1 problema resolvido com consenso >= 75%
- [ ] C√≥digo Pydantic + motor b√°sico comitado

### M√©dio Prazo (2 semanas)
- [ ] SACI completo (5 rodadas, converg√™ncia sem√¢ntica)
- [ ] Problema da f√°brica resolvido via SACI
- [ ] UI Streamlit para monitoramento

### Longo Prazo (1 m√™s)
- [ ] SACI em produ√ß√£o como servi√ßo
- [ ] 10+ problemas resolvidos com sucesso
- [ ] Open-source release (GitHub)

---

**FIM DA ESPECIFICA√á√ÉO SACI v1.0**

*Baseado em consenso de: Gemini 2.5 PRO, GPT-5 CODEX, Grok 4, Claude 3.5 Sonnet*  
*Data: 2025-10-23*
