"""
SACI ANTIGA - Debug dos Problemas da SACI EVOLUÃDA
Usa os 4 MODELOS ORIGINAIS do consenso.
"""

import asyncio
from llm_client import chat

PROBLEMA_CONTEXT = """
# PROBLEMAS ENCONTRADOS NA SACI EVOLUÃDA

## CONTEXTO
Durante testes da SACI EVOLUÃDA (implementada com consenso 4/4 models), 
foram identificados 2 problemas crÃ­ticos em 15 rodadas de debates reais:

## PROBLEMA 1: Similaridade SemÃ¢ntica Sempre 0.0

**EvidÃªncias:**
- Debate 1 (IntegraÃ§Ã£o FlashSoft): 5 rodadas, todas com similarity=0.000
- Debate 2 (vs. Devin): 5 rodadas, todas com similarity=0.000
- Debate Teste (Database): 5 rodadas, todas com similarity=0.000

**ImplementaÃ§Ã£o:**
```python
def compute_semantic_similarity(texts: List[str], timeout: int = 10) -> float:
    try:
        client = OpenAI()
        embeddings = []
        for text in texts:
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=text[:8000]
            )
            embeddings.append(response.data[0].embedding)
        
        similarities = []
        for i in range(len(embeddings)):
            for j in range(i+1, len(embeddings)):
                cos_sim = np.dot(embeddings[i], embeddings[j]) / (
                    np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])
                )
                similarities.append(cos_sim)
        
        return float(np.mean(similarities))
    except Exception:
        return 0.0  # Fallback silencioso
```

**HipÃ³teses:**
- A) ExceÃ§Ã£o silenciosa sempre (fallback 0.0)
- B) API OpenAI nÃ£o configurada/timeout
- C) Embeddings calculados mas similarity incorreta
- D) Bug no cÃ¡lculo de cosine similarity

**Impacto:**
- Score mÃ¡ximo possÃ­vel = 0.4 (apenas votos)
- Early stopping nunca ativa (threshold 0.75 inatingÃ­vel)

---

## PROBLEMA 2: Threshold 0.75 Muito Alto

**EvidÃªncias:**
- Debate 1: Consenso claro (75% votos D), mas score max=0.339
- Debate 2: DivergÃªncia real, score max=0.162

**CÃ¡lculo Atual:**
```python
score = (0.6 * 0.000) + (0.4 * vote_consensus)
      = 0.4 * vote_consensus

# Para atingir 0.75:
vote_consensus >= 1.875  # IMPOSSÃVEL (max=1.0)
```

**HipÃ³teses:**
- A) Threshold deveria ser 0.40 (apenas votos)
- B) Pesos deveriam ser invertidos (0.4 semantic, 0.6 votes)
- C) Threshold deveria ser adaptativo
- D) Bug de embeddings mascara problema real

---

## QUESTÃ•ES PARA DEBATE

1. Causa raiz do bug de embeddings?
2. Threshold 0.75 Ã© realista se embeddings funcionassem?
3. Qual problema atacar primeiro?
4. Sistema deveria continuar funcionando sem embeddings?
"""

DEBATE_PROMPT = """
VocÃª Ã© um modelo especializado em debugging e design de sistemas.

**PROBLEMA SUBMETIDO:**
{context}

**SUA TAREFA:**
1. Analise as evidÃªncias apresentadas
2. Priorize os problemas por severidade
3. Proponha diagnÃ³stico para causa raiz
4. Sugira ordem de correÃ§Ã£o
5. Vote em UMA das opÃ§Ãµes:

**OPÃ‡Ã•ES DE DIAGNÃ“STICO:**

**A:** Bug de embeddings Ã© crÃ­tico, fix imediato (threshold Ã© consequÃªncia)
**B:** Threshold estÃ¡ errado, ajustar primeiro (embeddings podem esperar)
**C:** Design fundamentalmente falho, refatorar mÃ©tricas completamente
**D:** Ambos sÃ£o bugs independentes, corrigir em paralelo
**E:** Sistema funciona bem sÃ³ com votos, remover embeddings

**FORMATO DE RESPOSTA:**
```json
{{
  "diagnostico": "Sua anÃ¡lise detalhada",
  "prioridade": ["problema_1", "problema_2"],
  "causa_raiz_embeddings": "HipÃ³tese A/B/C/D",
  "causa_raiz_threshold": "HipÃ³tese A/B/C/D",
  "ordem_correcao": "Qual atacar primeiro e por quÃª",
  "impacto_estimado": "Severidade 1-10 para cada",
  "voto": "A/B/C/D/E",
  "confianca": 80
}}
```

Seja brutalmente honesto e tÃ©cnico.
"""

async def run_saci_antiga_debug():
    """Executa debate com SACI antiga - MODELOS ORIGINAIS."""
    
    models = [
        "anthropic/claude-sonnet-4.5",
        "openai/gpt-5-codex",
        "google/gemini-2.5-pro",
        "x-ai/grok-4"
    ]
    
    print("\n" + "="*80)
    print("ğŸ” SACI ANTIGA - DEBUG DOS PROBLEMAS DA SACI EVOLUÃDA")
    print("="*80)
    print(f"\nğŸ“‹ Modelos participantes: {len(models)}")
    for i, model in enumerate(models, 1):
        print(f"   {i}. {model}")
    
    print("\nğŸ¯ Iniciando rodada de diagnÃ³stico...\n")
    
    responses = []
    
    for i, model in enumerate(models, 1):
        print(f"â³ Consultando {model.split('/')[-1]}...")
        
        try:
            prompt = DEBATE_PROMPT.format(context=PROBLEMA_CONTEXT)
            
            content = await asyncio.to_thread(
                chat,
                model=model,
                system="VocÃª Ã© um especialista em debugging e design de sistemas.",
                user=prompt,
                temperature=0.7,
                max_tokens=2000
            )
            
            responses.append({
                "model": model,
                "response": content
            })
            
            print(f"âœ… Resposta recebida ({len(content)} chars)\n")
            
        except Exception as e:
            print(f"âŒ Erro ao consultar {model}: {e}\n")
            responses.append({
                "model": model,
                "response": f"ERROR: {str(e)}"
            })
    
    print("\n" + "="*80)
    print("ğŸ’¾ Salvando resultados...")
    print("="*80 + "\n")
    
    with open("logs/saci_antiga_debug_problemas.md", "w", encoding="utf-8") as f:
        f.write("# SACI ANTIGA - DIAGNÃ“STICO DOS PROBLEMAS DA SACI EVOLUÃDA\n\n")
        f.write("**Modelos Originais do Consenso SACI EVOLUÃDO**\n\n")
        f.write("---\n\n")
        
        for i, resp in enumerate(responses, 1):
            model_name = resp['model'].split('/')[-1]
            f.write(f"## ğŸ¤– RESPOSTA {i}: {model_name}\n\n")
            f.write(f"**Model ID:** `{resp['model']}`\n\n")
            f.write("### DiagnÃ³stico:\n\n")
            f.write(resp['response'])
            f.write("\n\n---\n\n")
        
        f.write("## ğŸ“Š ANÃLISE DE CONSENSO\n\n")
        f.write("**Extrair votos manualmente de cada resposta JSON**\n")
    
    print("âœ… Resultados salvos em: logs/saci_antiga_debug_problemas.md")
    
    print("\n" + "="*80)
    print("ğŸ“„ PREVIEW DAS RESPOSTAS")
    print("="*80 + "\n")
    
    for i, resp in enumerate(responses, 1):
        model_name = resp['model'].split('/')[-1]
        preview = resp['response'][:300] + "..." if len(resp['response']) > 300 else resp['response']
        print(f"ğŸ¤– {model_name}:")
        print(preview)
        print("\n" + "-"*80 + "\n")
    
    print("âœ… Debate concluÃ­do!")
    print(f"ğŸ“Š {len(responses)}/{len(models)} modelos responderam\n")

if __name__ == "__main__":
    asyncio.run(run_saci_antiga_debug())
